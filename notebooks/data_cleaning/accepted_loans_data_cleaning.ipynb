{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba7d9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yj/v54tzbn14gb70ts6s0j5s3xm0000gn/T/ipykernel_1690/674185456.py:8: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  accepted_df = pd.read_csv(\"/Users/abubakaral-faki/Documents/Data Project/MPV1/data/raw/accepted_2007_to_2018Q4.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Start timer\n",
    "start_timer = time.time()\n",
    "\n",
    "#Convert accepted_loans data to Panda DataFrame\n",
    "accepted_df = pd.read_csv(\"/Users/abubakaral-faki/Documents/Data Project/MPV1/data/raw/accepted_2007_to_2018Q4.csv\")\n",
    "\n",
    "# End timer\n",
    "end_timer = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3da7046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data took 18.75 seconds to load.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data took {end_timer - start_timer:.2f} seconds to load.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cefbad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
      "0  68407277        NaN     3600.0       3600.0           3600.0   36 months   \n",
      "1  68355089        NaN    24700.0      24700.0          24700.0   36 months   \n",
      "2  68341763        NaN    20000.0      20000.0          20000.0   60 months   \n",
      "3  66310712        NaN    35000.0      35000.0          35000.0   60 months   \n",
      "4  68476807        NaN    10400.0      10400.0          10400.0   60 months   \n",
      "\n",
      "   int_rate  installment grade sub_grade  ... hardship_payoff_balance_amount  \\\n",
      "0     13.99       123.03     C        C4  ...                            NaN   \n",
      "1     11.99       820.28     C        C1  ...                            NaN   \n",
      "2     10.78       432.66     B        B4  ...                            NaN   \n",
      "3     14.85       829.90     C        C5  ...                            NaN   \n",
      "4     22.45       289.91     F        F1  ...                            NaN   \n",
      "\n",
      "  hardship_last_payment_amount disbursement_method  debt_settlement_flag  \\\n",
      "0                          NaN                Cash                     N   \n",
      "1                          NaN                Cash                     N   \n",
      "2                          NaN                Cash                     N   \n",
      "3                          NaN                Cash                     N   \n",
      "4                          NaN                Cash                     N   \n",
      "\n",
      "  debt_settlement_flag_date settlement_status settlement_date  \\\n",
      "0                       NaN               NaN             NaN   \n",
      "1                       NaN               NaN             NaN   \n",
      "2                       NaN               NaN             NaN   \n",
      "3                       NaN               NaN             NaN   \n",
      "4                       NaN               NaN             NaN   \n",
      "\n",
      "  settlement_amount settlement_percentage settlement_term  \n",
      "0               NaN                   NaN             NaN  \n",
      "1               NaN                   NaN             NaN  \n",
      "2               NaN                   NaN             NaN  \n",
      "3               NaN                   NaN             NaN  \n",
      "4               NaN                   NaN             NaN  \n",
      "\n",
      "[5 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "#create a copy of data frame to work with temporarily before applying changes to original 'accepted_df' DataFrame\n",
    "accepted_df_copy = pd.DataFrame(accepted_df)\n",
    "\n",
    "print(accepted_df_copy.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20ff412b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_title\n",
       "Teacher                                38824\n",
       "Manager                                34298\n",
       "Owner                                  21977\n",
       "Registered Nurse                       15867\n",
       "Driver                                 14753\n",
       "                                       ...  \n",
       "Electronic System Engineer                 1\n",
       "Substitute Teacher/Paraprofessional        1\n",
       "eligiblity worker                          1\n",
       "Escalated Customer Service Advisor         1\n",
       "Current Operations Officer                 1\n",
       "Name: count, Length: 512694, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_df_copy['emp_title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624e469d",
   "metadata": {},
   "source": [
    "### Create a CSV of each column and it's datatype for manual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d7d0ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Variables Data Type\n",
      "0                       id    object\n",
      "1                member_id   float64\n",
      "2                loan_amnt   float64\n",
      "3              funded_amnt   float64\n",
      "4          funded_amnt_inv   float64\n",
      "..                     ...       ...\n",
      "146      settlement_status    object\n",
      "147        settlement_date    object\n",
      "148      settlement_amount   float64\n",
      "149  settlement_percentage   float64\n",
      "150        settlement_term   float64\n",
      "\n",
      "[151 rows x 2 columns]\n",
      "Successfully saved variable_data_types_df as a csv.\n"
     ]
    }
   ],
   "source": [
    "# Get data types of each variable\n",
    "variable_data_types_df = accepted_df.dtypes.reset_index()\n",
    "\n",
    "# Rename columns\n",
    "variable_data_types_df.columns = ['Variables', 'Data Type']\n",
    "print(variable_data_types_df)\n",
    "\n",
    "#Save as csv\n",
    "try:\n",
    "    file_path = '/Users/abubakaral-faki/Documents/Data Project/MPV1/temp_files/variables_data_type.csv'\n",
    "    \n",
    "    variable_data_types_df.to_csv(file_path, index = False)\n",
    "    print(\"Successfully saved variable_data_types_df as a csv.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0550f",
   "metadata": {},
   "source": [
    "## Convert Date columns to Date Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e022d546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# Convert Date_columns to Date Data types\n",
    "date_columns = ['issue_d', 'earliest_cr_line', 'last_pymnt_d', 'next_pymnt_d',\n",
    "                'last_credit_pull_d', 'sec_app_earliest_cr_line', 'hardship_start_date',\n",
    "                'hardship_end_date', 'payment_plan_start_date', 'debt_settlement_flag_date', 'settlement_date']\n",
    "\n",
    "print(len(date_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4add6a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68     Sep-2017\n",
       "99     Nov-2017\n",
       "105    Jan-2018\n",
       "143    May-2018\n",
       "144    Sep-2017\n",
       "Name: settlement_date, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check format of date before converting to date objects\n",
    "\n",
    "# We use dropna to drop all missing values in a columns because sometimes the first few rows have missing values\n",
    "\n",
    "accepted_df.settlement_date.dropna().head() # Date format \"%b-$Y\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcfec36",
   "metadata": {},
   "source": [
    "## Check if all dates in each column are the same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad3e486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'issue_d' follows format '%b-%Y': True\n",
      "Column 'earliest_cr_line' follows format '%b-%Y': True\n",
      "Column 'last_pymnt_d' follows format '%b-%Y': True\n",
      "Column 'next_pymnt_d' follows format '%b-%Y': True\n",
      "Column 'last_credit_pull_d' follows format '%b-%Y': True\n",
      "Column 'sec_app_earliest_cr_line' follows format '%b-%Y': True\n",
      "Column 'hardship_start_date' follows format '%b-%Y': True\n",
      "Column 'hardship_end_date' follows format '%b-%Y': True\n",
      "Column 'payment_plan_start_date' follows format '%b-%Y': True\n",
      "Column 'debt_settlement_flag_date' follows format '%b-%Y': True\n",
      "Column 'settlement_date' follows format '%b-%Y': True\n"
     ]
    }
   ],
   "source": [
    "# Function to check format of date columns\n",
    "def validate_date_format(series, date_format = '%b-%Y'):\n",
    "    try:\n",
    "        pd.to_datetime(series, format = date_format, errors = 'raise')\n",
    "        return True\n",
    "        \n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "#Check is all columns have same format '%b-%Y' e.g. Sep-2017\n",
    "validation_results = {col: validate_date_format(accepted_df[col]) for col in date_columns}\n",
    "\n",
    "# Display results of validate_results\n",
    "for column, is_valid in validation_results.items():\n",
    "    print(f\"Column '{column}' follows format '%b-%Y': {is_valid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e98ae21",
   "metadata": {},
   "source": [
    "## Convert all date_columns to datetime64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "177deebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2015-12-01\n",
      "1   2015-12-01\n",
      "2   2015-12-01\n",
      "3   2015-12-01\n",
      "4   2015-12-01\n",
      "Name: issue_d, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Specify the correct format: %b for abbreviated month name, %Y for 4-digit year\n",
    "date_format = \"%b-%Y\"\n",
    "\n",
    "# Convert date columns efficiently using the specified format\n",
    "accepted_df_copy[date_columns] = accepted_df_copy[date_columns].apply(lambda col: pd.to_datetime(col,format =  date_format, errors = 'coerce'))\n",
    "\n",
    "# Check if dates were formatted correctly\n",
    "print(accepted_df_copy.issue_d.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3fc42f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issue_d                      datetime64[ns]\n",
       "earliest_cr_line             datetime64[ns]\n",
       "last_pymnt_d                 datetime64[ns]\n",
       "next_pymnt_d                 datetime64[ns]\n",
       "last_credit_pull_d           datetime64[ns]\n",
       "sec_app_earliest_cr_line     datetime64[ns]\n",
       "hardship_start_date          datetime64[ns]\n",
       "hardship_end_date            datetime64[ns]\n",
       "payment_plan_start_date      datetime64[ns]\n",
       "debt_settlement_flag_date    datetime64[ns]\n",
       "settlement_date              datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if all date columns are datetime datetypes\n",
    "accepted_df_copy[date_columns].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b96bdcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all date columns are datetime datetypes\n",
    "assert all(accepted_df_copy[col].dtype == 'datetime64[ns]' for col in date_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b37f6d",
   "metadata": {},
   "source": [
    "## Convert categorical columns to 'category' type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba40d5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Categorical columns to category\n",
    "\n",
    "categorical_columns = ['term', 'grade', 'sub_grade', 'emp_length', 'home_ownership',\n",
    "                       'verification_status', 'loan_status', 'pymnt_plan', 'purpose'\n",
    "                       ,'addr_state', 'initial_list_status', 'application_type',\n",
    "                       'hardship_flag', 'hardship_type', 'hardship_reason', 'hardship_status',\n",
    "                       'hardship_loan_status', 'disbursement_method', 'debt_settlement_flag',\n",
    "                       'settlement_status']\n",
    "\n",
    "accepted_df_copy[categorical_columns] = accepted_df_copy[categorical_columns].apply(lambda col: col.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7c36b9d-09a6-423c-ab39-93cb5841c39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>pymnt_plan</th>\n",
       "      <th>purpose</th>\n",
       "      <th>addr_state</th>\n",
       "      <th>initial_list_status</th>\n",
       "      <th>application_type</th>\n",
       "      <th>hardship_flag</th>\n",
       "      <th>hardship_type</th>\n",
       "      <th>hardship_reason</th>\n",
       "      <th>hardship_status</th>\n",
       "      <th>hardship_loan_status</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>settlement_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2260668</td>\n",
       "      <td>2260668</td>\n",
       "      <td>2260668</td>\n",
       "      <td>2113761</td>\n",
       "      <td>2260668</td>\n",
       "      <td>2260668</td>\n",
       "      <td>2260668</td>\n",
       "      <td>2260668</td>\n",
       "      <td>2260668</td>\n",
       "      <td>2260668</td>\n",
       "      <td>2260668</td>\n",
       "      <td>2260668</td>\n",
       "      <td>2260668</td>\n",
       "      <td>10917</td>\n",
       "      <td>10917</td>\n",
       "      <td>10917</td>\n",
       "      <td>10917</td>\n",
       "      <td>2260668</td>\n",
       "      <td>2260668</td>\n",
       "      <td>34246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>36 months</td>\n",
       "      <td>B</td>\n",
       "      <td>C1</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>Fully Paid</td>\n",
       "      <td>n</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>CA</td>\n",
       "      <td>w</td>\n",
       "      <td>Individual</td>\n",
       "      <td>N</td>\n",
       "      <td>INTEREST ONLY-3 MONTHS DEFERRAL</td>\n",
       "      <td>NATURAL_DISASTER</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>Late (16-30 days)</td>\n",
       "      <td>Cash</td>\n",
       "      <td>N</td>\n",
       "      <td>ACTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1609754</td>\n",
       "      <td>663557</td>\n",
       "      <td>145903</td>\n",
       "      <td>748005</td>\n",
       "      <td>1111450</td>\n",
       "      <td>886231</td>\n",
       "      <td>1076751</td>\n",
       "      <td>2260048</td>\n",
       "      <td>1277877</td>\n",
       "      <td>314533</td>\n",
       "      <td>1535467</td>\n",
       "      <td>2139958</td>\n",
       "      <td>2259836</td>\n",
       "      <td>10917</td>\n",
       "      <td>2965</td>\n",
       "      <td>7819</td>\n",
       "      <td>4770</td>\n",
       "      <td>2182546</td>\n",
       "      <td>2226422</td>\n",
       "      <td>14704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              term    grade sub_grade emp_length home_ownership  \\\n",
       "count      2260668  2260668   2260668    2113761        2260668   \n",
       "unique           2        7        35         11              6   \n",
       "top      36 months        B        C1  10+ years       MORTGAGE   \n",
       "freq       1609754   663557    145903     748005        1111450   \n",
       "\n",
       "       verification_status loan_status pymnt_plan             purpose  \\\n",
       "count              2260668     2260668    2260668             2260668   \n",
       "unique                   3           9          2                  14   \n",
       "top        Source Verified  Fully Paid          n  debt_consolidation   \n",
       "freq                886231     1076751    2260048             1277877   \n",
       "\n",
       "       addr_state initial_list_status application_type hardship_flag  \\\n",
       "count     2260668             2260668          2260668       2260668   \n",
       "unique         51                   2                2             2   \n",
       "top            CA                   w       Individual             N   \n",
       "freq       314533             1535467          2139958       2259836   \n",
       "\n",
       "                          hardship_type   hardship_reason hardship_status  \\\n",
       "count                             10917             10917           10917   \n",
       "unique                                1                 9               3   \n",
       "top     INTEREST ONLY-3 MONTHS DEFERRAL  NATURAL_DISASTER       COMPLETED   \n",
       "freq                              10917              2965            7819   \n",
       "\n",
       "       hardship_loan_status disbursement_method debt_settlement_flag  \\\n",
       "count                 10917             2260668              2260668   \n",
       "unique                    5                   2                    2   \n",
       "top       Late (16-30 days)                Cash                    N   \n",
       "freq                   4770             2182546              2226422   \n",
       "\n",
       "       settlement_status  \n",
       "count              34246  \n",
       "unique                 3  \n",
       "top               ACTIVE  \n",
       "freq               14704  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_df_copy[categorical_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "931f077a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term                    category\n",
       "grade                   category\n",
       "sub_grade               category\n",
       "emp_length              category\n",
       "home_ownership          category\n",
       "verification_status     category\n",
       "loan_status             category\n",
       "pymnt_plan              category\n",
       "purpose                 category\n",
       "addr_state              category\n",
       "initial_list_status     category\n",
       "application_type        category\n",
       "hardship_flag           category\n",
       "hardship_type           category\n",
       "hardship_reason         category\n",
       "hardship_status         category\n",
       "hardship_loan_status    category\n",
       "disbursement_method     category\n",
       "debt_settlement_flag    category\n",
       "settlement_status       category\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if categorical columns are of categorical data type\n",
    "\n",
    "accepted_df_copy[categorical_columns].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65f290d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if all cetagorical columns are now of category type\n",
    "\n",
    "assert all(accepted_df_copy[col].dtype == 'category' for col in categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9b4d963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Debt consolidation\n",
       "1                    Business\n",
       "2                         NaN\n",
       "3          Debt consolidation\n",
       "4              Major purchase\n",
       "                  ...        \n",
       "2260696                   NaN\n",
       "2260697    Debt consolidation\n",
       "2260698                   NaN\n",
       "2260699                   NaN\n",
       "2260700                   NaN\n",
       "Name: title, Length: 2260701, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the title column will require some cleaning because the categories appear in a messy format so I am converting back to a strings\n",
    "\n",
    "'''\n",
    "['\\tcredit_card', '\\tdebt_consolidation', '\\thouse', '\\tother', ..., 'zxcvb', '~Life Reorganization~', \n",
    "'~Summer Fun~', 'îîMY FIRST CAR îî']\n",
    "\n",
    "'''\n",
    "\n",
    "accepted_df_copy['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d33d86",
   "metadata": {},
   "source": [
    "# Convert 'id' column to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b98a0f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      2260701\n",
      "unique     2260701\n",
      "top       68407277\n",
      "freq             1\n",
      "Name: id, dtype: int64\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#check if 'id' column has any missing values\n",
    "print(accepted_df_copy['id'].describe())\n",
    "\n",
    "#convert id column from objext(text) to int\n",
    "\n",
    "'''This code below didn't work because there is a row that is a string representing this value;\n",
    " 'Total amount funded in policy code 1: 6417608175'\n",
    "'''\n",
    "#accepted_df_copy['id'] = accepted_df_copy['id'].astype(int)\n",
    "\n",
    "# Check if all entries are numbers\n",
    "print(all(accepted_df_copy['id'].astype(str).str.isdigit()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c10a37fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 non-int rows identified in id column\n",
      "\n",
      "\n",
      "421095     Total amount funded in policy code 1: 6417608175\n",
      "421096     Total amount funded in policy code 2: 1944088810\n",
      "528961     Total amount funded in policy code 1: 1741781700\n",
      "528962      Total amount funded in policy code 2: 564202131\n",
      "651664     Total amount funded in policy code 1: 1791201400\n",
      "651665      Total amount funded in policy code 2: 651669342\n",
      "749520     Total amount funded in policy code 1: 1443412975\n",
      "749521      Total amount funded in policy code 2: 511988838\n",
      "877716     Total amount funded in policy code 1: 2063142975\n",
      "877717      Total amount funded in policy code 2: 823319310\n",
      "983169     Total amount funded in policy code 1: 1538432075\n",
      "983170      Total amount funded in policy code 2: 608903141\n",
      "1117058    Total amount funded in policy code 1: 2087217200\n",
      "1117059     Total amount funded in policy code 2: 662815446\n",
      "1352689    Total amount funded in policy code 1: 3503840175\n",
      "1352690     Total amount funded in policy code 2: 873652739\n",
      "1481103    Total amount funded in policy code 1: 2050909275\n",
      "1481104     Total amount funded in policy code 2: 820109297\n",
      "1611877    Total amount funded in policy code 1: 2080429200\n",
      "1611878     Total amount funded in policy code 2: 737901574\n",
      "1651665            Loans that do not meet the credit policy\n",
      "1654415     Total amount funded in policy code 1: 460296150\n",
      "1654416             Total amount funded in policy code 2: 0\n",
      "1751196    Total amount funded in policy code 1: 1437969475\n",
      "1751197     Total amount funded in policy code 2: 520780182\n",
      "1939379    Total amount funded in policy code 1: 2700702175\n",
      "1939380      Total amount funded in policy code 2: 81866225\n",
      "2038501    Total amount funded in policy code 1: 1404586950\n",
      "2038502     Total amount funded in policy code 2: 567447023\n",
      "2157151    Total amount funded in policy code 1: 1817354125\n",
      "2157152     Total amount funded in policy code 2: 620899600\n",
      "2260699    Total amount funded in policy code 1: 1465324575\n",
      "2260700     Total amount funded in policy code 2: 521953170\n",
      "Name: id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# identify all rows in 'id' column that are not integers\n",
    "\n",
    "non_int_rows = accepted_df_copy[~accepted_df_copy['id'].apply(lambda x: str(x).isdigit())] #33 rows\n",
    "\n",
    "print(len(non_int_rows['id']), 'non-int rows identified in id column')\n",
    "print('\\n')\n",
    "print(non_int_rows['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1367d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns associated with non-int rows in 'id' columns are empty\n"
     ]
    }
   ],
   "source": [
    "# check if all columns associated with the non_int_rows in 'id' column are empty\n",
    "\n",
    "col_not_empty = non_int_rows.drop(columns=['id']).isna().all(axis=1)\n",
    "\n",
    "if (col_not_empty.all() == True):\n",
    "    print('All columns associated with non-int rows in \\'id\\' columns are empty')\n",
    "else:\n",
    "    print('All columns associated with non-int rows in \\'id\\' columns are\\'nt empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "00a4b551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accepted_df shape before removing rows: (2260701, 151)\n",
      "Indexes of Non-integer rows to drop : Index([ 421095,  421096,  528961,  528962,  651664,  651665,  749520,  749521,\n",
      "        877716,  877717,  983169,  983170, 1117058, 1117059, 1352689, 1352690,\n",
      "       1481103, 1481104, 1611877, 1611878, 1651665, 1654415, 1654416, 1751196,\n",
      "       1751197, 1939379, 1939380, 2038501, 2038502, 2157151, 2157152, 2260699,\n",
      "       2260700],\n",
      "      dtype='int64')\n",
      "\n",
      "non-int rows to remove: 33\n",
      "\n",
      "\n",
      "33 successfully dropped\n",
      "\n",
      "\n",
      "accepted_df shape after removing rows: (2260668, 151)\n"
     ]
    }
   ],
   "source": [
    "# Drop all non-int rows in id column\n",
    "\n",
    "print('accepted_df shape before removing rows:', accepted_df_copy.shape) #Get shape of accepted_df Dataframe before dropping rows\n",
    "\n",
    "# Step 1 - Get index of non-int rows in 'id' column to drop\n",
    "nonint_rows_todrop = non_int_rows.index\n",
    "\n",
    "print(f\"Indexes of Non-integer rows to drop : {nonint_rows_todrop}\\n\")\n",
    "print(f\"non-int rows to remove: {len(nonint_rows_todrop)}\\n\\n\")\n",
    "\n",
    "# Step 2 - remove non-int rows in 'id' column from accepted_df_copy\n",
    "accepted_df_copy = accepted_df_copy.drop(index = nonint_rows_todrop)\n",
    "print(len(nonint_rows_todrop), 'successfully dropped\\n\\n')\n",
    "\n",
    "# Step 3 - Check accepted_df shape to confirm if 32 rows were dropped\n",
    "\n",
    "print('accepted_df shape after removing rows:', accepted_df_copy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ace5091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>funded_amnt_inv</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>hardship_payoff_balance_amount</th>\n",
       "      <th>hardship_last_payment_amount</th>\n",
       "      <th>disbursement_method</th>\n",
       "      <th>debt_settlement_flag</th>\n",
       "      <th>debt_settlement_flag_date</th>\n",
       "      <th>settlement_status</th>\n",
       "      <th>settlement_date</th>\n",
       "      <th>settlement_amount</th>\n",
       "      <th>settlement_percentage</th>\n",
       "      <th>settlement_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, member_id, loan_amnt, funded_amnt, funded_amnt_inv, term, int_rate, installment, grade, sub_grade, emp_title, emp_length, home_ownership, annual_inc, verification_status, issue_d, loan_status, pymnt_plan, url, desc, purpose, title, zip_code, addr_state, dti, delinq_2yrs, earliest_cr_line, fico_range_low, fico_range_high, inq_last_6mths, mths_since_last_delinq, mths_since_last_record, open_acc, pub_rec, revol_bal, revol_util, total_acc, initial_list_status, out_prncp, out_prncp_inv, total_pymnt, total_pymnt_inv, total_rec_prncp, total_rec_int, total_rec_late_fee, recoveries, collection_recovery_fee, last_pymnt_d, last_pymnt_amnt, next_pymnt_d, last_credit_pull_d, last_fico_range_high, last_fico_range_low, collections_12_mths_ex_med, mths_since_last_major_derog, policy_code, application_type, annual_inc_joint, dti_joint, verification_status_joint, acc_now_delinq, tot_coll_amt, tot_cur_bal, open_acc_6m, open_act_il, open_il_12m, open_il_24m, mths_since_rcnt_il, total_bal_il, il_util, open_rv_12m, open_rv_24m, max_bal_bc, all_util, total_rev_hi_lim, inq_fi, total_cu_tl, inq_last_12m, acc_open_past_24mths, avg_cur_bal, bc_open_to_buy, bc_util, chargeoff_within_12_mths, delinq_amnt, mo_sin_old_il_acct, mo_sin_old_rev_tl_op, mo_sin_rcnt_rev_tl_op, mo_sin_rcnt_tl, mort_acc, mths_since_recent_bc, mths_since_recent_bc_dlq, mths_since_recent_inq, mths_since_recent_revol_delinq, num_accts_ever_120_pd, num_actv_bc_tl, num_actv_rev_tl, num_bc_sats, num_bc_tl, num_il_tl, num_op_rev_tl, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 151 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if we still have non-int rows in 'id' column\n",
    "accepted_df_copy[~accepted_df_copy['id'].apply(lambda row: str(row).isdigit())] #Should return an empty DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06fd5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soooo now we can finally Convert 'id' column to integer\n",
    "accepted_df_copy['id'] = accepted_df_copy['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c50e64aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 2260668 entries, 0 to 2260698\n",
      "Series name: id\n",
      "Non-Null Count    Dtype\n",
      "--------------    -----\n",
      "2260668 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 34.5 MB\n"
     ]
    }
   ],
   "source": [
    "accepted_df_copy['id'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34da039",
   "metadata": {},
   "source": [
    "### Check for other variables of type 'object' so we can convert to the right type if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23dd9a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     variable    type\n",
      "10                  emp_title  object\n",
      "18                        url  object\n",
      "19                       desc  object\n",
      "21                      title  object\n",
      "22                   zip_code  object\n",
      "59  verification_status_joint  object\n"
     ]
    }
   ],
   "source": [
    "#Get data types of all variables and convert it to a DataFrame\n",
    "var_data_types = pd.DataFrame(accepted_df_copy.dtypes)\n",
    "\n",
    "# Reset index of Dataframe\n",
    "var_data_types = var_data_types.reset_index()\n",
    "\n",
    "#define column names\n",
    "var_data_types.columns = ['variable', 'type']\n",
    "\n",
    "#Get variables that are type 'object'\n",
    "object_vars = var_data_types[var_data_types['type'] == 'object']\n",
    "\n",
    "print(object_vars)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162bca34",
   "metadata": {},
   "source": [
    "# Cleaning emp_title column\n",
    "\n",
    "Convert emp_title to categorical variable and remove leading whitespaces from category names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e11d82cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['\\tCFO', '\\tMultimedia Supervisor', '\\tSlot technician',\n",
       "       '\\tVP - Operations', ' ', ' \\tASR II', ' \\tAdv Mtr Proj Fld Rep',\n",
       "       ' \\tAuto Body Repair', ' \\tDriver', ' \\tEmployee Strategies Manager',\n",
       "       ...\n",
       "       'zueck transportation', 'zulily', '{Owner}Truck Driver',\n",
       "       '| Principal Business Solution Architect|',\n",
       "       'År.  Technical Illustrator', '​Associate Tech Support Analyst',\n",
       "       '​Financial Analyst', '​License Compliance Investigator',\n",
       "       '​Senior IT Field Support', '👨‍🍳 '],\n",
       "      dtype='object', length=512694)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert emp_title to category or leave as oject\n",
    "accepted_df_copy['emp_title'] = accepted_df_copy['emp_title'].astype('category')\n",
    "\n",
    "#Check type of emp_title\n",
    "accepted_df_copy['emp_title'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2de6223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_title</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Teacher</td>\n",
       "      <td>38824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manager</td>\n",
       "      <td>34298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Owner</td>\n",
       "      <td>21977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Registered Nurse</td>\n",
       "      <td>15867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Driver</td>\n",
       "      <td>14753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512689</th>\n",
       "      <td>IT Specialsit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512690</th>\n",
       "      <td>IT Specialpist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512691</th>\n",
       "      <td>IT Speciality</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512692</th>\n",
       "      <td>IT Specialists</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512693</th>\n",
       "      <td>👨‍🍳</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>512694 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               emp_title  count\n",
       "0                Teacher  38824\n",
       "1                Manager  34298\n",
       "2                  Owner  21977\n",
       "3       Registered Nurse  15867\n",
       "4                 Driver  14753\n",
       "...                  ...    ...\n",
       "512689     IT Specialsit      1\n",
       "512690    IT Specialpist      1\n",
       "512691     IT Speciality      1\n",
       "512692    IT Specialists      1\n",
       "512693              👨‍🍳       1\n",
       "\n",
       "[512694 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "career_list = accepted_df_copy['emp_title'].value_counts().reset_index()\n",
    "\n",
    "career_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e4643326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166969"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_df_copy['emp_title'].isna().sum() # count number of Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8afe64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Categories to CSV file for manual check\n",
    "\n",
    "file_path = '/Users/abubakaral-faki/Documents/Data Project/MPV1/temp_files/emp_title_categories.csv'\n",
    "\n",
    "categories = accepted_df_copy['emp_title'].cat.categories\n",
    "\n",
    "pd.DataFrame({'job_titles': categories}).to_csv(file_path, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49a72bf",
   "metadata": {},
   "source": [
    "From a quick overview of the CSV file I saw:\n",
    "\n",
    "1.) numbers as job_titles\n",
    "2.) job titles containing emojis\n",
    "3.) duplicate Job_titles with spelling or formating differences\n",
    "4.) text like this 'ÄãFinancial Analyst'\n",
    "5.) Leading white spaces represented by '\\t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c13dbda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'emp_title' back to string/object in Panadas\n",
    "accepted_df_copy['emp_title'] = accepted_df_copy['emp_title'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a646dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Leading White spaces and Normalize text\n",
    "accepted_df_copy['emp_title'] = accepted_df_copy['emp_title'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9d877359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_title\n",
       "nan                                         166969\n",
       "teacher                                      48460\n",
       "manager                                      45852\n",
       "owner                                        33591\n",
       "registered nurse                             23354\n",
       "                                             ...  \n",
       "greenhouse manager/research project coor         1\n",
       "sr. qa tech                                      1\n",
       "committee legislative assistant                  1\n",
       "avp, client administration                       1\n",
       "exec dir internal audit                          1\n",
       "Name: count, Length: 411811, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_df_copy['emp_title'].value_counts() # Check Value counts after standardizing text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6733bd5f",
   "metadata": {},
   "source": [
    "## Remove numbers that are job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a507437f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0132', '03', '0301', '0321', '04', '1', '10', '1052', '1099', '11', '112', '12', '121000', '13', '14', '1400', '14000', '15', '15000', '16', '17', '1811', '19', '2', '20', '21', '22', '25', '25312', '3', '30', '30005', '30304', '36000', '37', '38645', '4', '45000', '48000', '5', '553742017', '59106', '6', '6048', '7', '8', '9', '911', '9652651']\n",
      "\n",
      "There are  49 job titles as numbers\n"
     ]
    }
   ],
   "source": [
    "#all job_titles as numbers in emp_title\n",
    "number_job_titles = [title for title in categories if str(title).isdigit() == True]\n",
    "\n",
    "print(number_job_titles)\n",
    "\n",
    "print('\\nThere are ', len(number_job_titles), 'job titles as numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c78c9f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp_title\n",
      "1            13\n",
      "3            12\n",
      "8             9\n",
      "5             8\n",
      "12            7\n",
      "10            7\n",
      "11            6\n",
      "4             4\n",
      "2             4\n",
      "911           4\n",
      "20            3\n",
      "15            3\n",
      "14            3\n",
      "6             3\n",
      "21            2\n",
      "17            2\n",
      "112           2\n",
      "16            2\n",
      "7             1\n",
      "1052          1\n",
      "0132          1\n",
      "04            1\n",
      "25312         1\n",
      "30304         1\n",
      "1811          1\n",
      "9652651       1\n",
      "30            1\n",
      "553742017     1\n",
      "121000        1\n",
      "1400          1\n",
      "36000         1\n",
      "37            1\n",
      "1099          1\n",
      "30005         1\n",
      "59106         1\n",
      "03            1\n",
      "38645         1\n",
      "19            1\n",
      "6153          1\n",
      "15000         1\n",
      "9             1\n",
      "25            1\n",
      "45000         1\n",
      "48000         1\n",
      "0321          1\n",
      "22            1\n",
      "14000         1\n",
      "6048          1\n",
      "0301          1\n",
      "13            1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Check frequency of numeric Job_title to check if they are important\n",
    "\n",
    "numeric_titles = accepted_df_copy[accepted_df_copy['emp_title'].str.isdigit()]\n",
    "\n",
    "print(numeric_titles['emp_title'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5e08fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove numeric titles expect for 911 and 112 as 911 and 112 are numbers for emmergency services\n",
    "import numpy as np\n",
    "import re\n",
    "keep_titles = ['911', '112']\n",
    "\n",
    "\n",
    "def remove_numeric_job_tiles(title):\n",
    "    ''' This function takes a column from a Dataframe and Keeps Numerics Job titles like 911 and 112\n",
    "    But repaces other numeric job_titles with NaN'''\n",
    "    \n",
    "    if pd.isna(title): #Handle Missing Values to avoid errors\n",
    "        return np.nan\n",
    "    \n",
    "    #Covert title to string and strip\n",
    "    title_str = str(title).strip().lower()\n",
    "    \n",
    "    # Check if record is '911' or '112'\n",
    "    if title_str in keep_titles:\n",
    "        return title_str\n",
    "    \n",
    "    # Check job titles that have numbers in them e.g. '2nd pressman'\n",
    "    if title_str.isdigit() and title_str not in keep_titles:\n",
    "        return False # Replace meaningless numeric titles with NaN\n",
    "    \n",
    "    return title #Keep non-numeric titles unchanged\n",
    "\n",
    "\n",
    "# Apply remove_numeric_job_tiles function to accepted_df_copy dataframe\n",
    "# accepted_df_copy = accepted_df_copy[accepted_df_copy['emp_title'].apply(remove_numeric_job_tiles)].index #Store indexes of\n",
    "\n",
    "accepted_df_copy['emp_title'] = accepted_df_copy['emp_title'].apply(remove_numeric_job_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05d73ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16225      911\n",
      "116912     112\n",
      "755033     911\n",
      "900893     911\n",
      "1465253    112\n",
      "1696755    911\n",
      "Name: emp_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Check if we only have 6 numeric titles  \n",
    "# - Recall we had six '911' titles and two '112' titles\n",
    "\n",
    "print(accepted_df_copy['emp_title'][accepted_df_copy['emp_title'].str.isdigit() == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "36b3a9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2260668, 151)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_df_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53bb0fd",
   "metadata": {},
   "source": [
    "## Remove commas periods and emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "15020f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>emp_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>470285</th>\n",
       "      <td>40000.0</td>\n",
       "      <td>`</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588940</th>\n",
       "      <td>25000.0</td>\n",
       "      <td>👨‍🍳</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677396</th>\n",
       "      <td>36000.0</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         annual_inc emp_title\n",
       "470285      40000.0         `\n",
       "1588940     25000.0       👨‍🍳\n",
       "1677396     36000.0         ."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Ensure emp_title is a string and handle NaNs\n",
    "accepted_df_copy['emp_title'] = accepted_df_copy['emp_title'].astype(str).fillna('')\n",
    "\n",
    "# Function to check if a string consists only of special characters (excluding emojis)\n",
    "def is_special_chars_only(text):\n",
    "    text = text.strip()  # Remove spaces\n",
    "    return bool(re.fullmatch(r\"^[^\\w\\s-]+$\", text))  # Matches only special characters (no letters/numbers)\n",
    "\n",
    "'''def is_special_chars_only(text):\n",
    "    # Remove common emoji unicode ranges from being considered \"special characters\"\n",
    "    return pd.NA if (re.fullmatch(r'^[^\\w\\s\\U0001F300-\\U0001F9FF]+$', text)) else text'''\n",
    "\n",
    "# Apply filtering: Remove rows where emp_title consists only of special characters\n",
    "special_characters = accepted_df_copy[accepted_df_copy['emp_title'].apply(is_special_chars_only)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "special_characters[['annual_inc', 'emp_title']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa35b12f-17c4-4fc0-be01-68141e97ef9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([470285, 1588940, 1677396], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "special_characters_index = special_characters['emp_title'].index\n",
    "print(special_characters_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4b449b46-2e9f-4a51-92e2-4f73370ec9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(accepted_df_copy.columns.get_loc('emp_title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6d0e1ca-188e-493d-8f77-f8800a86ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace special characters\n",
    "replace_chef_emoji = \"👨‍🍳\"\n",
    "\n",
    "for item in special_characters_index:\n",
    "    # Replace chef emoji(👨‍🍳) with 'chef'\n",
    "    if accepted_df_copy.loc[item, 'emp_title'] == replace_chef_emoji:\n",
    "        accepted_df_copy.loc[item, 'emp_title'] = 'chef'\n",
    "    else:\n",
    "        # Replace Special characters with empty string \"\"\n",
    "        accepted_df_copy.loc[item, 'emp_title'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "71dd3e52-ddde-4d2f-a640-a721044ce826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "470285         \n",
       "1588940    chef\n",
       "1677396        \n",
       "Name: emp_title, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_df_copy.loc[special_characters_index,'emp_title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bccbc1c",
   "metadata": {},
   "source": [
    "# Identify misspelt Job titles in 'emp_title' using Fuzzy Matching Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f81c6675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thefuzz in /Users/abubakaral-faki/anaconda3/lib/python3.11/site-packages (0.22.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.0.0 in /Users/abubakaral-faki/anaconda3/lib/python3.11/site-packages (from thefuzz) (3.11.0)\n"
     ]
    }
   ],
   "source": [
    "#Install require package to use fuzzy matching algorithm\n",
    "!pip install thefuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b3bebc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nan', 'teacher', 'manager', 'owner', 'registered nurse', 'supervisor', 'driver', 'sales', 'rn', 'office manager', 'project manager', 'general manager', 'truck driver', 'director', 'president', 'engineer', 'sales manager', 'operations manager', 'police officer', 'vice president', 'technician']\n"
     ]
    }
   ],
   "source": [
    "# create a list of top 20 job titles in dataset to correct\n",
    "titles_to_correct = list(pd.DataFrame(accepted_df_copy['emp_title'].value_counts(ascending = False)).reset_index()['emp_title'][:21])\n",
    "\n",
    "#remove 'nan' string values\n",
    "print(titles_to_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cf50372c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nan', 'teacher', 'owner', 'registered nurse', 'supervisor', 'driver', 'sales', 'rn', 'truck driver', 'director', 'president', 'engineer', 'police officer', 'vice president', 'technician']\n"
     ]
    }
   ],
   "source": [
    "# remove office manager, manager, project manager, general manager, sales manager, operations manager\n",
    "\n",
    "remove_titles = {'manager', 'office manager', 'project manager', 'general manager', 'sales manager', 'operations manager'}\n",
    "titles_to_correct = [job for job in titles_to_correct if job not in remove_titles]\n",
    "\n",
    "print(titles_to_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2355b42f",
   "metadata": {},
   "source": [
    "# Correct mispelled 'teacher' job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "14a3e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure job titles are lowercase and stripped of spaces\n",
    "accepted_df_copy['c_emp_title'] = accepted_df_copy['emp_title']\n",
    "accepted_df_copy['c_emp_title'] = accepted_df_copy['c_emp_title'].astype(str).str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7d77e459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_title\n",
       "nan                                         166969\n",
       "teacher                                      48460\n",
       "manager                                      45852\n",
       "owner                                        33591\n",
       "registered nurse                             23354\n",
       "                                             ...  \n",
       "animal care tech 2                               1\n",
       "food corriditor manger                           1\n",
       "special worker                                   1\n",
       "assistant vice president - mortgage comp         1\n",
       "exec dir internal audit                          1\n",
       "Name: count, Length: 411761, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_df_copy['emp_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db4cea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_emp_title\n",
      "nan                   166969\n",
      "teacher                48829\n",
      "manager                45852\n",
      "owner                  33591\n",
      "registered nurse       23354\n",
      "supervisor             22306\n",
      "driver                 22267\n",
      "sales                  18984\n",
      "rn                     17196\n",
      "office manager         14231\n",
      "project manager        13842\n",
      "general manager        13317\n",
      "truck driver           12797\n",
      "director               10595\n",
      "president               9826\n",
      "engineer                8978\n",
      "sales manager           8532\n",
      "operations manager      8183\n",
      "police officer          7675\n",
      "vice president          7625\n",
      "Name: count, dtype: int64\n",
      "Exceution time: 1.09 seconds.\n"
     ]
    }
   ],
   "source": [
    "from thefuzz import process\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Get unique job titles\n",
    "unique_titles = accepted_df_copy['c_emp_title'].dropna().unique()\n",
    "\n",
    "# Start timer\n",
    "start_timer = time.time()\n",
    "\n",
    "# Use `process.extract()` to find closest matches to \"teacher\"\n",
    "teachers = process.extract('teacher', unique_titles, limit=len(unique_titles))\n",
    "\n",
    "# Filter matches to keep only those with a similarity score of 80 or higher\n",
    "teachers_filtered = [(job, score) for job, score in teachers if score >= 91]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_teachers = pd.DataFrame(teachers_filtered, columns=['Job Title', 'Similarity Score'])\n",
    "\n",
    "# Sort by similarity score in descending order\n",
    "df_teachers = df_teachers.sort_values(by='Similarity Score', ascending=False)\n",
    "\n",
    "# Create a mapping dictionary\n",
    "teacher_map = {job: 'teacher' for job, score in teachers_filtered}\n",
    "teachers_dict = pd.DataFrame(list(teacher_map.items()), columns = ['original job title', 'Mapped Job Title'])\n",
    "teachers_dict.to_csv('/Users/abubakaral-faki/Documents/Data Project/MPV1/temp_files/teachers_map.csv', index = False)\n",
    "\n",
    "# Efficiently update values using `.map()`\n",
    "#accepted_df_copy['c_emp_title'] = accepted_df_copy['c_emp_title'].map(teacher_map).fillna(accepted_df_copy['c_emp_title'])\n",
    "accepted_df_copy.loc[accepted_df_copy['c_emp_title'].isin(teacher_map.keys()), 'c_emp_title'] = 'teacher'\n",
    "\n",
    "# End timer\n",
    "end_timer = time.time()\n",
    "\n",
    "# Save results to CSV file\n",
    "file_location = '/Users/abubakaral-faki/Documents/Data Project/MPV1/temp_files/teachers_similarity_scores.csv'\n",
    "df_teachers.to_csv(file_location, index=False)\n",
    "\n",
    "# Check updated value counts\n",
    "print(accepted_df_copy['c_emp_title'].value_counts()[:20])\n",
    "\n",
    "print(f\"Exceution time: {end_timer - start_timer:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc2144",
   "metadata": {},
   "source": [
    "# Correct mispelled 'sales' job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "935c7087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_emp_title\n",
      "nan                   166969\n",
      "teacher                48829\n",
      "manager                45852\n",
      "owner                  33591\n",
      "registered nurse       23354\n",
      "supervisor             22306\n",
      "driver                 22267\n",
      "sales                  19003\n",
      "rn                     17196\n",
      "office manager         14231\n",
      "project manager        13842\n",
      "general manager        13317\n",
      "truck driver           12797\n",
      "director               10595\n",
      "president               9826\n",
      "engineer                8978\n",
      "sales manager           8532\n",
      "operations manager      8183\n",
      "police officer          7675\n",
      "vice president          7625\n",
      "Name: count, dtype: int64\n",
      "Exceution time: 0.97 seconds.\n"
     ]
    }
   ],
   "source": [
    "from thefuzz import process\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Get unique job titles\n",
    "unique_titles = accepted_df_copy['c_emp_title'].dropna().unique()\n",
    "\n",
    "# Start timer\n",
    "start_timer = time.time()\n",
    "\n",
    "\n",
    "# Use `process.extract()` to find closest matches to \"sales\"\n",
    "sales = process.extract('sales', unique_titles, limit=len(unique_titles))\n",
    "\n",
    "# Filter matches to keep only those with a similarity score of 80 or higher\n",
    "sales_filtered = [(job, score) for job, score in sales if score > 90]\n",
    "\n",
    "# Convert to DataFrame\n",
    "sales_df = pd.DataFrame(sales_filtered, columns=['Job Title', 'Similarity Score'])\n",
    "\n",
    "# Sort by similarity score in descending order\n",
    "sales_df = sales_df.sort_values(by='Similarity Score', ascending=False)\n",
    "\n",
    "# Create a mapping dictionary\n",
    "sales_map = {job: 'sales' for job, score in sales_filtered}\n",
    "\n",
    "# Efficiently update values using `.map()`\n",
    "#accepted_df_copy['c_emp_title'] = accepted_df_copy['c_emp_title'].map(teacher_map).fillna(accepted_df_copy['c_emp_title'])\n",
    "accepted_df_copy.loc[accepted_df_copy['c_emp_title'].isin(sales_map.keys()), 'c_emp_title'] = 'sales'\n",
    "\n",
    "# End timer\n",
    "end_timer = time.time()\n",
    "\n",
    "# Save results to CSV file\n",
    "file_location = '/Users/abubakaral-faki/Documents/Data Project/MPV1/temp_files/job_title_matches/teachers_similarity_scores.csv'\n",
    "sales_df.to_csv(file_location, index=False)\n",
    "\n",
    "# Check updated value counts\n",
    "print(accepted_df_copy['c_emp_title'].value_counts()[:20])\n",
    "\n",
    "print(f\"Exceution time: {end_timer - start_timer:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f1672",
   "metadata": {},
   "source": [
    "# Correct mispelled 'owner' job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7ef573b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_emp_title\n",
      "nan                   166969\n",
      "teacher                48829\n",
      "manager                45852\n",
      "owner                  33719\n",
      "registered nurse       23354\n",
      "supervisor             22306\n",
      "driver                 22267\n",
      "sales                  19003\n",
      "rn                     17196\n",
      "office manager         14231\n",
      "project manager        13842\n",
      "general manager        13317\n",
      "truck driver           12797\n",
      "director               10595\n",
      "president               9826\n",
      "engineer                8978\n",
      "sales manager           8532\n",
      "operations manager      8183\n",
      "police officer          7675\n",
      "vice president          7625\n",
      "Name: count, dtype: int64\n",
      "Exceution time: 0.99 seconds.\n"
     ]
    }
   ],
   "source": [
    "from thefuzz import process\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Get unique job titles\n",
    "unique_titles = accepted_df_copy['c_emp_title'].dropna().unique()\n",
    "\n",
    "# Start timer\n",
    "start_timer = time.time()\n",
    "\n",
    "\n",
    "# Use `process.extract()` to find closest matches to \"owner\"\n",
    "owner = process.extract('owner', unique_titles, limit=len(unique_titles))\n",
    "\n",
    "# Filter matches to keep only those with a similarity score of 91 or higher\n",
    "owner_filtered = [(job, score) for job, score in owner if score >= 91]\n",
    "\n",
    "# Convert to DataFrame\n",
    "owner_df = pd.DataFrame(owner_filtered, columns=['Job Title', 'Similarity Score'])\n",
    "\n",
    "# Sort by similarity score in descending order\n",
    "owner_df = owner_df.sort_values(by='Similarity Score', ascending = False)\n",
    "\n",
    "# Create a mapping dictionary\n",
    "owner_map = {job: 'sales' for job, score in owner_filtered}\n",
    "\n",
    "# Efficiently update values using `.map()`\n",
    "#accepted_df_copy['c_emp_title'] = accepted_df_copy['c_emp_title'].map(teacher_map).fillna(accepted_df_copy['c_emp_title'])\n",
    "accepted_df_copy.loc[accepted_df_copy['c_emp_title'].isin(owner_map.keys()), 'c_emp_title'] = 'owner'\n",
    "\n",
    "# End timer\n",
    "end_timer = time.time()\n",
    "\n",
    "# Save results to CSV file\n",
    "file_location = '/Users/abubakaral-faki/Documents/Data Project/MPV1/temp_files/job_title_matches/owner_similarity_scores.csv'\n",
    "sales_df.to_csv(file_location, index=False)\n",
    "\n",
    "# Check updated value counts\n",
    "print(accepted_df_copy['c_emp_title'].value_counts()[:20])\n",
    "\n",
    "print(f\"Exceution time: {end_timer - start_timer:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f747f",
   "metadata": {},
   "source": [
    "# Drop 'url' column it if not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5717d1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68407277</td>\n",
       "      <td>https://lendingclub.com/browse/loanDetail.action?loan_id=68407277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68355089</td>\n",
       "      <td>https://lendingclub.com/browse/loanDetail.action?loan_id=68355089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68341763</td>\n",
       "      <td>https://lendingclub.com/browse/loanDetail.action?loan_id=68341763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66310712</td>\n",
       "      <td>https://lendingclub.com/browse/loanDetail.action?loan_id=66310712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68476807</td>\n",
       "      <td>https://lendingclub.com/browse/loanDetail.action?loan_id=68476807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                                                url\n",
       "0  68407277  https://lendingclub.com/browse/loanDetail.action?loan_id=68407277\n",
       "1  68355089  https://lendingclub.com/browse/loanDetail.action?loan_id=68355089\n",
       "2  68341763  https://lendingclub.com/browse/loanDetail.action?loan_id=68341763\n",
       "3  66310712  https://lendingclub.com/browse/loanDetail.action?loan_id=66310712\n",
       "4  68476807  https://lendingclub.com/browse/loanDetail.action?loan_id=68476807"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect url Column\n",
    "pd.set_option('display.max_colwidth', None) #make sure pandas doesn't truncate the url column\n",
    "\n",
    "\n",
    "accepted_df_copy[['id', 'url']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc57c38a",
   "metadata": {},
   "source": [
    "Seems like the 'url' gets info for each specific 'id'. \n",
    "\n",
    "Let's check if the id from the id column matches the id in\n",
    "in the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "45b75072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the loan_id from the url using a regular expression\n",
    "extracted_id = accepted_df_copy['url'].str.extract(r'loan_id=(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "98d805e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  68407277\n",
      "1  68355089\n",
      "2  68341763\n",
      "3  66310712\n",
      "4  68476807\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#Check if the id was extracted correctly from the url\n",
    "print(extracted_id.head())\n",
    "\n",
    "# Check type of extracted_id\n",
    "print(type(extracted_id[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70fb844",
   "metadata": {},
   "source": [
    "#### Convert extracted_id to same datatype as 'id'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d62e3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of 'id' column is int64\n",
      "Type of 'extracted_id' is int64\n"
     ]
    }
   ],
   "source": [
    "#Check dtype of id column\n",
    "print('Type of \\'id\\' column is', accepted_df_copy['id'].dtype)\n",
    "\n",
    "#Change dtype of extracted_id columns to 'int'\n",
    "extracted_id[0] = extracted_id[0].astype('int')\n",
    "\n",
    "#Check dtype of extracted_id column\n",
    "print('Type of \\'extracted_id\\' is', extracted_id[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2436cf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Check if all id's between 'extracted_id' column and 'id' column match\n",
    "\n",
    "all_match = (accepted_df_copy['id'] == extracted_id[0]).all()\n",
    "\n",
    "print(all_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d436436",
   "metadata": {},
   "source": [
    "#### We can drop url column since there no mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4a6cc854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before drop:  (2260668, 152)\n"
     ]
    }
   ],
   "source": [
    "# Shape before dropping 'url'\n",
    "print('Shape before drop: ', accepted_df_copy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fb21994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'url' column\n",
    "accepted_df_copy = accepted_df_copy.drop('url', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "97cea891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after drop:  (2260668, 151)\n"
     ]
    }
   ],
   "source": [
    "# Shape after dropping 'url'\n",
    "print('Shape after drop: ', accepted_df_copy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6925160",
   "metadata": {},
   "source": [
    "### Inspect 'desc' column and change 'desc' column to the right datatype if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37b7973",
   "metadata": {},
   "source": [
    "'desc' contains information about the loan description wriiten by the borrower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0fcf17b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "Name: desc, dtype: object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(accepted_df_copy['desc'].head())\n",
    "\n",
    "print(accepted_df_copy['desc'].dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ade6c7",
   "metadata": {},
   "source": [
    "#### Notes from code above\n",
    "From checking the data type of 'desc' and the first few rows it seems this column might be empty.\n",
    "\n",
    "'desc' contains information about the loan description form the borrower.\n",
    "\n",
    "We will rename this column to make it more intuitive to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fd681b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 2260668 entries, 0 to 2260698\n",
      "Series name: desc\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "126065 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 99.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Check if all values in the 'desc' column are all NaN\n",
    "\n",
    "print(accepted_df_copy['desc'].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "04039ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2134603\n"
     ]
    }
   ],
   "source": [
    "#count nuber of Null Values in 'desc' column\n",
    "\n",
    "print(accepted_df_copy['desc'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7cf2d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change name of column 'desc' to 'loan_purpose'\n",
    "accepted_df_copy = accepted_df_copy.rename(columns = {'desc': 'loan_purpose'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "389af3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 2260668 entries, 0 to 2260698\n",
      "Series name: loan_purpose\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "126065 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 99.0+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check if name change happened\n",
    "\n",
    "accepted_df_copy['loan_purpose'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c3258331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2134603\n"
     ]
    }
   ],
   "source": [
    "#Check for missing values in 'desc'/'loan_purpose'\n",
    "print(accepted_df_copy['loan_purpose'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "56d30c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan,\n",
       "       'We knew that using our credit cards to finance an adoption would squeeze us, but then medical and other unexpected expenses made the situation almost impossible. We are a stable family in a stable community. We just need to break a cycle of debt that is getting worse.',\n",
       "       \"I had a bad year two years ago, with some late and missed payments. I'm doing much better now, but I've got fees and some higher interest bits that have added up on top of the other stuff, and it's a little crazy. I'm hoping doing it thru Lending Club will make it easier - and cheaper - to pay off.\",\n",
       "       ...,\n",
       "       'This loan will be used solely to consolidate credit card debts accrued while wife was/is unemployed.',\n",
       "       'I have recently purchased and built a new home that I have always dreamed of having.  I would like to complete the project by putting a hottub in my backyard, however; I am not happy with the rate I  have been offered from GE to finance the spa.  I am paying cash for all other improvements, but this is the final phase and finishing touch to my happiness.  I am in the process of consolidating a lot of debt, and went through a minor period of financial woes, but through determination and hard work I have managed to rebound.  My income is fantastic, and I would pay cash for the item, but would like to reserve the money I have saved for future issues if they should arise.  I am a college graduate, responsible, and work for a very good company that is stable in this very unstable market.  I plan to repay this loan in less than 12 months with a 4th quarter bonus I will be receiving.  Thank you for your consideration.',\n",
       "       'To whom it may concern,     Hello, my name is David McLean.  I am requesting a loan to consolidate some high interest revolving credit.    The interest rates go anywhere from 14-29.9%.  I am a very reliable person that meets his obligations and pays his debts.   In nearly 15 years, I have not missed or been late on a payment except once due to an oversight.   I have a stable life and home with a good job of nearly 6yrs with plans of retiring from there.  Thank you for your thoughtful consideration.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_df_copy['loan_purpose'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc475dd-e0ce-4a60-88bb-7406927763bd",
   "metadata": {},
   "source": [
    "# Drop member_id columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fe7fcf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "member_id successfuly dropped\n"
     ]
    }
   ],
   "source": [
    "# Drop member_id column \n",
    "# All values for memeber_id are missing\n",
    "\n",
    "accepted_df_copy.drop('member_id', axis = 1, inplace = True)\n",
    "\n",
    "print('member_id successfuly dropped')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c2aceb",
   "metadata": {},
   "source": [
    "## Export version 1 of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7426e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a Version of the dataset with all columns cleaned except 'title' and 'employee'\n",
    "file_path = \"/Users/abubakaral-faki/Documents/Data Project/MPV1/data/interim/v1-accepted.csv\"\n",
    "\n",
    "accepted_df_copy.to_csv(file_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1a1f4f35-4cb5-44b3-85ee-f904c604569f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n",
      "id                                int64\n",
      "loan_amnt                       float64\n",
      "funded_amnt                     float64\n",
      "funded_amnt_inv                 float64\n",
      "term                           category\n",
      "                              ...      \n",
      "settlement_date          datetime64[ns]\n",
      "settlement_amount               float64\n",
      "settlement_percentage           float64\n",
      "settlement_term                 float64\n",
      "c_emp_title                      object\n",
      "Length: 150, dtype: object\n"
     ]
    }
   ],
   "source": [
    "columns_dtypes = accepted_df_copy[accepted_df_copy.columns].dtypes\n",
    "print(columns_dtypes.shape)\n",
    "print(columns_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e81e74ef-a0b2-4eb6-a75b-3f4f06eda852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loan_amnt</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funded_amnt</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>funded_amnt_inv</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>term</td>\n",
       "      <td>category</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            column     dtype\n",
       "0               id     int64\n",
       "1        loan_amnt   float64\n",
       "2      funded_amnt   float64\n",
       "3  funded_amnt_inv   float64\n",
       "4             term  category"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_dtypes_df = columns_dtypes.reset_index()\n",
    "\n",
    "columns_dtypes_df.columns = ['column', 'dtype']\n",
    "\n",
    "columns_dtypes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "23cbb176-c3d7-4e0f-bc05-922fc7140ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Users/abubakaral-faki/Documents/Data Project/MPV1/temp_files/column_dtypes.csv\"\n",
    "columns_dtypes_df.to_csv(file_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1ccc4d-3e32-4ad7-b164-2073ee133983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
